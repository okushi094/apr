import React, { useState, useEffect } from 'react';
import {
  SafeAreaView,
  StyleSheet,
  Text,
  View,
  TouchableOpacity,
  PermissionsAndroid,
  ActivityIndicator,
} from 'react-native';
import Voice from '@react-native-voice/voice';
import BleManager from 'react-native-ble-manager';

const SERVICE_UUID = '6E400001-B5A3-F393-E0A9-E50E24DCCA9E';
const CHARACTERISTIC_UUID_RX = '6E400002-B5A3-F393-E0A9-E50E24DCCA9E';
const DEVICE_NAME = 'ESP32-Car';

// 音声コマンドとESP32のコマンド値のマッピング
const COMMANDS = {
  '進む': '1',
  '進んで': '1',
  '前進': '1',
  '止まれ': '0',
  '止まって': '0',
  'ストップ': '0',
  '左': '2',
  '左に寄せて': '2',
  '右': '3',
  '右に寄せて': '3',
};

// メインアプリケーションコンポーネント
const App = () => {
  const [device, setDevice] = useState(null);
  const [isScanning, setIsScanning] = useState(false);
  const [isConnecting, setIsConnecting] = useState(false);
  const [isConnected, setIsConnected] = useState(false);
  const [recognizedText, setRecognizedText] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isMicReady, setIsMicReady] = useState(false);

  // マイクのパーミッションをリクエスト
  useEffect(() => {
    const requestMicrophonePermission = async () => {
      try {
        const granted = await PermissionsAndroid.request(
          PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
          {
            title: 'マイクの許可',
            message: '音声認識のためにマイクの使用を許可してください',
            buttonNeutral: '後で',
            buttonNegative: '拒否',
            buttonPositive: '許可',
          },
        );
        if (granted === PermissionsAndroid.RESULTS.GRANTED) {
          console.log('マイクの許可がされました');
          setIsMicReady(true);
        } else {
          console.log('マイクの許可が拒否されました');
        }
      } catch (err) {
        console.warn(err);
      }
    };
    requestMicrophonePermission();
  }, []);

  // BLEマネージャーと音声認識の初期化
  useEffect(() => {
    BleManager.start({ showAlert: false }).then(() => {
      console.log('BleManager initialized');
    });

    Voice.onSpeechResults = (e) => {
      if (e.value && e.value.length > 0) {
        const text = e.value[0];
        setRecognizedText(text);
        console.log('認識されたテキスト:', text);
        sendCommand(text);
      }
    };

    Voice.onSpeechError = (e) => {
      console.error('音声認識エラー:', e);
      setIsListening(false);
    };

    Voice.onSpeechEnd = () => {
      setIsListening(false);
      console.log('音声認識終了');
    };

    return () => {
      Voice.destroy().then(Voice.removeAllListeners);
    };
  }, []);

  // BLEスキャン処理
  const startScan = () => {
    if (isScanning) return;

    setIsScanning(true);
    setDevice(null);
    setIsConnected(false);
    console.log('BLEスキャン開始');

    BleManager.scan([], 5, true)
      .then(() => {
        console.log('スキャン開始しました');
      })
      .catch((err) => {
        console.error('スキャンエラー:', err);
      });
  };

  // BLEデバイス発見時の処理
  useEffect(() => {
    const handleDiscoverPeripheral = (peripheral) => {
      console.log('発見したデバイス:', peripheral.name, peripheral.id);
      if (peripheral.name === DEVICE_NAME) {
        setDevice(peripheral);
        console.log('目的のデバイスを発見しました:', peripheral.name);
        BleManager.stopScan().then(() => {
          setIsScanning(false);
          console.log('スキャンを停止しました');
          connectToDevice(peripheral);
        });
      }
    };

    const handleStopScan = () => {
      console.log('スキャンが停止しました');
      setIsScanning(false);
    };

    BleManager.start().then(() => {
      BleManager.getConnectedPeripherals([]).then((peripherals) => {
        if (peripherals.length > 0) {
          // 既に接続されている場合
          const connectedDevice = peripherals.find(p => p.name === DEVICE_NAME);
          if (connectedDevice) {
            setDevice(connectedDevice);
            setIsConnected(true);
            console.log('既に接続されています:', connectedDevice.name);
          } else {
            startScan();
          }
        } else {
          startScan();
        }
      });
    });

    const listeners = [
      BleManager.addListener('BleManagerDiscoverPeripheral', handleDiscoverPeripheral),
      BleManager.addListener('BleManagerStopScan', handleStopScan),
    ];

    return () => {
      for (const listener of listeners) {
        listener.remove();
      }
    };
  }, []);

  // デバイスへの接続処理
  const connectToDevice = async (peripheral) => {
    if (isConnecting) return;

    setIsConnecting(true);
    console.log('接続開始:', peripheral.id);
    try {
      await BleManager.connect(peripheral.id);
      console.log('接続成功');
      setIsConnected(true);
    } catch (error) {
      console.error('接続エラー:', error);
      setIsConnected(false);
    } finally {
      setIsConnecting(false);
    }
  };

  // 音声認識の開始
  const startListening = async () => {
    if (!isConnected) {
      console.warn('BLEデバイスが接続されていません');
      return;
    }
    if (isListening) return;
    
    setRecognizedText('');
    setIsListening(true);
    try {
      await Voice.start('ja-JP');
      console.log('音声認識を開始しました');
    } catch (e) {
      console.error('音声認識開始エラー:', e);
      setIsListening(false);
    }
  };

  // コマンドの送信
  const sendCommand = (text) => {
    const commandValue = findCommand(text);
    if (commandValue === null) {
      console.log('有効なコマンドが見つかりませんでした');
      return;
    }
    const data = Buffer.from(commandValue, 'ascii');
    console.log(`コマンドを送信: ${commandValue}`);
    if (device) {
      BleManager.write(device.id, SERVICE_UUID, CHARACTERISTIC_UUID_RX, data)
        .then(() => {
          console.log('コマンド送信成功');
        })
        .catch((error) => {
          console.error('コマンド送信エラー:', error);
        });
    }
  };

  // テキストからコマンドを探す
  const findCommand = (text) => {
    const normalizedText = text.trim();
    for (const key in COMMANDS) {
      if (normalizedText.includes(key)) {
        return COMMANDS[key];
      }
    }
    return null;
  };

  const renderConnectionStatus = () => {
    if (isScanning || isConnecting) {
      return (
        <View style={styles.statusContainer}>
          <ActivityIndicator size="small" color="#fff" />
          <Text style={styles.statusText}>接続中...</Text>
        </View>
      );
    }
    if (isConnected) {
      return (
        <View style={[styles.statusContainer, { backgroundColor: '#4CAF50' }]}>
          <Text style={styles.statusText}>接続済み</Text>
        </View>
      );
    }
    return (
      <View style={[styles.statusContainer, { backgroundColor: '#F44336' }]}>
        <Text style={styles.statusText}>未接続</Text>
      </View>
    );
  };

  return (
    <SafeAreaView style={styles.container}>
      <View style={styles.header}>
        <Text style={styles.title}>音声制御カー</Text>
        {renderConnectionStatus()}
      </View>
      <View style={styles.content}>
        <Text style={styles.recognizedTextTitle}>認識されたテキスト:</Text>
        <Text style={styles.recognizedText}>{recognizedText || '音声コマンドを入力してください'}</Text>
        <TouchableOpacity
          style={[
            styles.micButton,
            { backgroundColor: isListening ? '#f00' : '#4CAF50' },
          ]}
          onPress={startListening}
          disabled={!isConnected || isListening}
        >
          {isListening ? (
            <Text style={styles.micButtonText}>聞取り中...</Text>
          ) : (
            <Text style={styles.micButtonText}>マイク</Text>
          )}
        </TouchableOpacity>
        {isListening && <ActivityIndicator size="large" color="#4CAF50" style={styles.listeningIndicator} />}
      </View>
      <View style={styles.footer}>
        <Text style={styles.footerText}>
          音声コマンド: 進む, 止まる, 左, 右
        </Text>
      </View>
    </SafeAreaView>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#f5f5f5',
  },
  header: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    padding: 20,
    backgroundColor: '#1E88E5',
  },
  title: {
    fontSize: 24,
    fontWeight: 'bold',
    color: '#fff',
  },
  statusContainer: {
    paddingVertical: 5,
    paddingHorizontal: 10,
    borderRadius: 20,
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'center',
  },
  statusText: {
    fontSize: 16,
    color: '#fff',
    marginLeft: 5,
  },
  content: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    padding: 20,
  },
  recognizedTextTitle: {
    fontSize: 18,
    color: '#333',
    marginBottom: 10,
  },
  recognizedText: {
    fontSize: 24,
    fontWeight: 'bold',
    color: '#555',
    marginBottom: 30,
    textAlign: 'center',
  },
  micButton: {
    width: 150,
    height: 150,
    borderRadius: 75,
    justifyContent: 'center',
    alignItems: 'center',
    elevation: 8,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 4 },
    shadowOpacity: 0.3,
    shadowRadius: 5,
  },
  micButtonText: {
    fontSize: 20,
    fontWeight: 'bold',
    color: '#fff',
  },
  listeningIndicator: {
    marginTop: 20,
  },
  footer: {
    padding: 20,
    backgroundColor: '#eee',
    alignItems: 'center',
  },
  footerText: {
    fontSize: 14,
    color: '#888',
  },
});

export default App;
